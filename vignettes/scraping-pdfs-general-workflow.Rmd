---
title: "General Workflow for Scraping PDF files"
author: "Joe DeVivo"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{General Workflow for Scraping PDFs}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Backgorund


## Overview of Steps
Basically there are three steps, each of which are described in detail below:

- Creating or updating the species dictionary file. 
- Getting files ready for porocessing.
- Processing the files and comparing against the dictionary

### Before you Start

## Creating a Dictionary File

## Getting files ready for processing


## Processing files


### How things are supposed to work


### What to do when things don't work


## Viewing Results

## Coming Soon
- SQL views for pdf files, taxonomy, and reference geolocations so that data are dynamically updated as they are edited/added in Data Store.
- Desktop application to QC the hit data.
- Additional R functions to identify potential outlier hits based on observation data from external repositories such as eBird, iNaturalist, iDigBio, and gBif.

